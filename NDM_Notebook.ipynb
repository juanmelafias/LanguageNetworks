{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries: \n",
    "import pandas as pd\n",
    "import numpy as np; \n",
    "import matplotlib.pyplot as plt; \n",
    "import matplotlib as mplt; \n",
    "import networkx as nx; \n",
    "from copy import copy; \n",
    "# For 3D scatter: \n",
    "from mpl_toolkits.mplot3d import Axes3D; \n",
    "\n",
    "# Importing libraries for I/O and system communication: \n",
    "import os, sys; \n",
    "import pickle as pkl; \n",
    "import scipy.io as sio; # To read .mat files! and .mnx files! \n",
    "\n",
    "# Importing functions for clustering: \n",
    "from sklearn.cluster import KMeans;  \n",
    "import scipy.cluster.hierarchy as spc; \n",
    "\n",
    "# Importing homebrew libraries: \n",
    "import helper as h; \n",
    "import loadHelper as lh; \n",
    "\n",
    "#importing functions\n",
    "\n",
    "from utils import csv2df,json2dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x233de72e800>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picsPath = 'pics/'\n",
    "netName = 'Spanish'\n",
    "langframe = csv2df(f'dataframes/{netName}.csv')\n",
    "mostfreq =langframe.unique_id.to_list()\n",
    "net = json2dict(f'dictionaries/{netName}.json')\n",
    "thisNetwork = nx.Graph()\n",
    "thisNetwork.add_nodes_from(net.keys())\n",
    "for (k, v) in net.items():\n",
    "    thisNetwork.add_edges_from(([(k, t) for t in v]))\n",
    "thisNetwork=thisNetwork.subgraph(mostfreq)\n",
    "netPath='networks/'\n",
    "thisNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'ls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Juan\\NodeMorphospaces\\NDM_Notebook.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Juan/NodeMorphospaces/NDM_Notebook.ipynb#ch0000012?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39;49mls()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'os' has no attribute 'ls'"
     ]
    }
   ],
   "source": [
    "os.lis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 2852\n"
     ]
    }
   ],
   "source": [
    "Gcc = sorted(nx.connected_components(thisNetwork), key=len, reverse=True); \n",
    "thisNetwork = nx.Graph(thisNetwork.subgraph(Gcc[0])); \n",
    "nNodes = len(thisNetwork.nodes()); \n",
    "nEdges = thisNetwork.number_of_edges(); \n",
    "print(nNodes,nEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fNeighborMean = True; \n",
    "fNeighborStd = True; \n",
    "if ((\"random\" not in netName) and (os.path.isfile(netPath + netName + \"_nodeList.csv\")) \n",
    "\t\t\t\t\t\t\t\tand (os.path.isfile(netPath + netName + \"_properties.pkl\"))): \n",
    "\t# Files already exist with properties that have been computed. We can proceed with these: \n",
    "\t# (nodeList, propertiesDict) = h.readNetworkProperties(netName, netPath); \n",
    "\t(nodeList, propertiesDict) = h.readNetworkProperties(netName, netPath, fNeighborMean, fNeighborStd); \n",
    "\t(includedProperties, excludedProperties) = h.findPathologicalProperties(propertiesDict); \n",
    "else: \n",
    "\t# Properties have not been saved for this network and need to be computed: \n",
    "\t(nodeList, propertiesDict, includedProperties, excludedProperties) = h.computeNodesProperties(thisNetwork, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfNeighborMean, fNeighborStd); \n",
    "\tif (\"random\" not in netName): \n",
    "\t\th.writeNetworkProperties(netName, netPath, nodeList, propertiesDict); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You want to read the files with the properties\n",
    "(nodeList, propertiesDict) = h.readNetworkProperties(netName, netPath, fNeighborMean, fNeighborStd); \n",
    "(includedProperties, excludedProperties) = h.findPathologicalProperties(propertiesDict); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing network\n",
      "\tList of nodes extracted. \n",
      "\tLargest connected component extracted. \n",
      "\tSelf loops removed. \n",
      "\tNetwork properties prepared. \n",
      "\tNeighbor mean and std added or excluded. \n",
      "\tDictionary initialized. \n",
      "Computing network stuff. \n",
      "\tComputing degree. \n",
      "\tComputing eigenvector centrality. \n",
      "\tComputing betweenness centrality. \n",
      "\tComputing closeness centrality. \n",
      "\tComputing harmonic centrality. \n",
      "\tComputing pagerank centrality. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juan\\NodeMorphospaces\\venv\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tComputing largest k-core. \n",
      "\tComputing onion layer. \n",
      "\tComputing effective size. \n",
      "\tComputing node clique number. \n",
      "\tComputing number of maximal cliques. \n",
      "\tComputing clustering. \n",
      "\tComputing square clustering. \n",
      "\tComputing closeness vitality. \n",
      "\tComputing node constraint. \n",
      "Post-processing: \n",
      "\tProperties sorted in lists. \n",
      "\tProperties for neighbors computed. \n",
      "\tProblematic properties reported. \n"
     ]
    }
   ],
   "source": [
    "#You want to save the properties\n",
    "(nodeList, propertiesDict, includedProperties, excludedProperties) = h.computeNodesProperties(thisNetwork, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfNeighborMean, fNeighborStd); \n",
    "if (\"random\" not in netName): \n",
    "\th.writeNetworkProperties(netName, netPath, nodeList, propertiesDict); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.449392712550607"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertiesDict['degree'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanpropertiesDict = {key:propertiesDict[key].mean() for key in propertiesDict.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dict2json\n",
    "jsonname = f'avgproperties/{netName}.json'\n",
    "dict2json(meanpropertiesDict,jsonname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2048</td>\n",
       "      <td>les</td>\n",
       "      <td>PRON</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id word   POS  count\n",
       "2047       2048  les  PRON     28"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langframe[langframe['unique_id']==2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ancient_Greek.json',\n",
       " 'Arabic.json',\n",
       " 'Armenian.json',\n",
       " 'Basque.json',\n",
       " 'Belarusian.json',\n",
       " 'Bulgarian.json',\n",
       " 'Catalan.json',\n",
       " 'Chinese.json',\n",
       " 'Classical_Chinese.json',\n",
       " 'Croatian.json',\n",
       " 'Czech.json',\n",
       " 'Danish.json',\n",
       " 'Dutch.json',\n",
       " 'English.json',\n",
       " 'Estonian.json',\n",
       " 'Finnish.json',\n",
       " 'French.json',\n",
       " 'Galician.json',\n",
       " 'German.json',\n",
       " 'Hebrew.json',\n",
       " 'Hindi.json',\n",
       " 'Icelandic.json',\n",
       " 'Indonesian.json',\n",
       " 'Irish.json',\n",
       " 'Italian.json',\n",
       " 'Japanese.json',\n",
       " 'Korean.json',\n",
       " 'Latin.json',\n",
       " 'Latvian.json',\n",
       " 'Lithuanian.json',\n",
       " 'Naija.json',\n",
       " 'Norwegian.json',\n",
       " 'Old_Church_Slavonic.json',\n",
       " 'Old_East_Slavic.json',\n",
       " 'Old_French.json',\n",
       " 'Persian.json',\n",
       " 'Polish.json',\n",
       " 'Portuguese.json',\n",
       " 'Romanian.json',\n",
       " 'Russian.json',\n",
       " 'Scottish_Gaelic.json',\n",
       " 'Serbian.json',\n",
       " 'Slovak.json',\n",
       " 'Slovenian.json',\n",
       " 'Spanish.json',\n",
       " 'Swedish.json',\n",
       " 'Turkish.json',\n",
       " 'Ukrainian.json',\n",
       " 'Urdu.json',\n",
       " 'Western_Armenian.json']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./dictionaries/')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cddcf39c8df6ba480f895cdfdb1db5017c3b68dfb41c39a576d47362d9c7b50"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
